---
title: "Análisis estadístico de las canciones más escuchadas de Spotify"
author: "Guillermo Ribero, Rafael Cabrera, Juan Camilo Rodriguez, David Melendez"
date: "5/24/2022"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
#library(tidyverse) #Pendiente ponerlo como taller 1 para que #sea automático
#library(readxl)
#library(MASS)
#library(fBasics)
#library(corrplot)
#library(factoextra)
#library(ggfortify)

packages = c("tidyverse","readxl","MASS","fBasics","corrplot","ggfortify","factoextra")

packages.check <- lapply(
  packages,
  FUN = function(x){
    if(!require(x,character.only = TRUE)){
      install.packages(x, dependencies = TRUE)
      library(x,character.only = TRUE)
    }
  }
)

songs_normalize <- read_excel("./songs_normalize_genre_fixed.xlsx", 
                              col_types = c("text", "text", "numeric",
                                            "text", "numeric", "numeric","numeric", 
                                            "numeric", "numeric","numeric", 
                                            "numeric", "numeric","numeric", 
                                            "numeric", "numeric","numeric", 
                                            "numeric", "text"))
complete_data_set <- songs_normalize
df_numeric_vals = subset(songs_normalize, select = -c(artist, song, explicit, year, genre, mode, key))


###############################################################

## Fisher Setup

songs_normalize_genre_fixed <- read_excel("./songs_normalize_genre_fixed.xlsx", 
                              col_types = c("text", "text", "numeric", 
                                            "text", "numeric", "numeric", "numeric", 
                                            "numeric", "numeric", "numeric", 
                                            "numeric", "numeric", "numeric", 
                                            "numeric", "numeric", "numeric", 
                                            "numeric", "text"))

#View(songs_normalize_genre_fixed)
dataset <- songs_normalize_genre_fixed


###########
#Creando la nueva variable categorica de popularity
# Baja de 0 a 30 
#Media de 31 a 60
#Alta de 61-86

column_pop = songs_normalize_genre_fixed$popularity
pop_cat = songs_normalize_genre_fixed
contador = 0 #Indice para saber donde poner la nueva cat O PUEDO SIMPLEMENTE REEMPLAZAR
for (i in column_pop){
  contador = contador+1;
  if (i<=30){
    #Agregar fila con popularidad baja que es un 0
    pop_cat$popularity[contador] = 0
  }else if(i<=60){#Pues como no entro en el anterior ya es mayor a 30 
    #Agregar fila con popularidad mediaque es un 1
    pop_cat$popularity[contador] = 1
  }else{#es decir es mayor a 60 
    #Agregar fila con popularidad alta que es un 2
    pop_cat$popularity[contador] = 2
  }
}
#View(pop_cat)
songs_normalize_genre_fixed <- pop_cat
#View(songs_normalize_genre_fixed)
datasetWithoutCategorical <- songs_normalize_genre_fixed
#View(datasetWithoutCategorical)

# Remove Categoriccal variables from the dataset, save that new dataset
datasetWithoutCategoricalFisherWithGenre <- dataset[,c(3,7,8,10,12:18)]
datasetWithoutCategoricalFisherWithPopularity <- dataset[,c(3,6,7,8,10,12:17)]
#View(datasetWithoutCategoricalFisherWithGenre)
#glimpse(songs_normalize_genre_fixed)
#glimpse(datasetWithoutCategorical)

```

-------

### Tabla de Contenidos

1. [Descripción del proyecto](#descripcion)
2. [Base de datos utilizada](#base-de-datos)
3. [Variables](#Variables)
4. [Análisis exploratorio de los datos](#Analisis-exploratorio)
* [Barplot](#Barplot)
* [Boxplots](#Boxplots)
* [Matriz de correlación](#Matriz-de-correlacion)
* [PCA](#PCA)
5. [Agrupamiento de los géneros musicales](#Agrupamiento-de-los-generos-musicales)
* [Discriminante lineal de Fisher con datos puros](#Discriminante-lineal-de-Fisher-con-datos-puros)
* [Discriminante lineal de Fisher con datos corregidos](#Discriminante-lineal-de-Fisher-con-datos-corregidos)
6. [Agrupamiento según nivel de popularidad](#Agrupamiento-segun-nivel-de-popularidad)
7. [Regresión lineal sobre niveles de energía](#Regresion-lineal)
8. [Conclusiones](#Conclusiones)
9. [Bibliografía](#Bibliografia)

-------


### <a name="descripcion"></a> Descripción del proyecto 

La era digital trajo consigo a las plataformas digitales tales como Spotify, Deezer, soundCloud y demás en las que los artistas indie buscan reconocimiento y dar su salto a la fama. Muchos para lograr su objetivo, le pagan a un intermediario como $tunecore_{[2]}$ el cual les ayuda a reducir el tiempo en que serán reconocidos y podrán hacer de su hobby una profesión. 

Para contribuir a los crecientes artistas particularmente en la plataforma de spotify, la cual según orpheusaudioacademy$_{[3]}$ paga entre 3 y 5 dolarés por cada 1000 reproducciones, por lo que harémos un estudio de los datos de las mejores canciones de Spotify entre los años 2000 a 2019$_{[1]}$ con el fin de comprender mejor que características tienen las mejores canciones.

-------

### <a name="base-de-datos"></a> Base de datos utilizada

Contiene las mejores 2000 canciones rankeadas entre los años 2000 a 2019, con 18 columnas que describen la canción y sus características tales como indices de popularidad, participación de la audiencia y demás. 

-------

### <a name="Variables"></a> Variables 
De las 18 variables disponibles en la base de datos usaremos las siguientes:

#### Categóricas 

* Key: La clave en la que esta la canción, si no se detecta ninguna vale -1. 
 
* Popularity: Valor entre 0 y 100 que indica que tan popular esta canción, para una mayor facilidad en su uso, la modificamos y ahora es una variable que toma los valores 0,1 o 2 según su popularidad así: 0 ->0-30, 1 -> 31-60 y 2 60-100.
 
* Genre: Genero de la canción, en algunos casos tenían varios así que solo dejamos el principal para poder realizar una buena agrupación.

#### Númericas

* Duration_ms: Duración de la canción en milisegundos.
 
* Danceability: Indice entre 0 y 1 que describe que tan bailable es una canción. 
 
* Energy: Indice entre 0 y 1 que describe la intensidad y actividad de una canción.
 
* Loudness: El volumen general de la canción medido en decibeles(db) y sus valores varían entre -60 a 0.
 
* Speechines: Detecta la presencia de palabras habladas en una canción y varía entre 0 a 1. 
 
* Acousticness: Un indice entre 0.0 y 1, que mide que tan acústica es una canción.
 
* Instrumentalness: Indice entre 0.0 y 1 sobre que tan compuesta por solo instrumentos es una canción, si se acerca mucho a 1, la canción tiene muy pocos vocales.
 
* Liveness: Indice entre 0 y 1 de cuanto participa la audiencia en la canción.
 
* Valence: Indice entre 0 y 1 que describe que tan positiva es una canción, es decir que tan alegre es una canción.
 
* Tempo: El estimado del ritmo de la canción medido en beats por minuto o BTM por sus siglas en ingles.

-------

### <a name="Analisis-exploratorio"></a> Análisis exploratorio de los datos (Incluye PCA+gráficas)

#### <a name="Barplot"></a> Barplot de observación según categoría $explicit$

```{r, echo = FALSE}
library(tidyverse)
ggplot(complete_data_set, aes(x = explicit, fill = explicit)) +
  geom_bar() +
  scale_fill_manual(values = c("purple", "orange"))
```

Según este barplot, es más probable que una canción se encuentre entre los 'Top 100' al crear una cancion no 'explicit'.

```{r, echo = FALSE, fig.align="center"}

ggplot(complete_data_set, aes(x = speechiness, y = popularity, color = factor(genre))) + geom_point()
```
Podemos observar una relacion interesante entre speechiness y popularity para hip hop, donde es necesario 
utilizar valores mas altos de speechiness para lograr mayor popularidad. Esto no parece afectar otros generos

```{r, echo = FALSE, fig.align="center"}

ggplot(complete_data_set, aes(x = acousticness, y = popularity, color = factor(genre))) + geom_point()
```
Podemos observar como la mayoria de los datos estan agrupados con valores pequeños de acousticness.
Se esta perdiendo el uso de musica acustica.

#### <a name="Boxplots"></a> Boxplots de las variables numéricas

```{r, echo=FALSE, fig.align="center"}
######## Grafico de boxplots de variables numéricas
par(mfrow = c(3,4))
boxplot(df_numeric_vals$duration_ms, outline = FALSE)
title("Duración en ms")
boxplot(df_numeric_vals$popularity, outline = FALSE)
title("Indice de popularidad")
boxplot(df_numeric_vals$danceability, outline = FALSE)
title("Indice de bailabilidad")
boxplot(df_numeric_vals$energy, outline = FALSE)
title("Indice de energia")
boxplot(df_numeric_vals$loudness, outline = FALSE)
title("Indice de loudness")
boxplot(df_numeric_vals$speechiness, outline = FALSE)
title("Indice de speechines")
boxplot(df_numeric_vals$acousticness, outline = FALSE)
title("Indice de acousticness")
boxplot(df_numeric_vals$instrumentalness, outline = FALSE)
title("Indice de instrumentalidad")
boxplot(df_numeric_vals$liveness, outline = FALSE)
title("Indice de vida")
boxplot(df_numeric_vals$valence, outline = FALSE)
title("Indice de valance")
boxplot(df_numeric_vals$tempo, outline = FALSE)
title("Indice de tempo")
```


#### <a name="Matriz-de-correlacion"></a> Matriz de correlación de las variables numéricas
```{r, echo=FALSE, warning=FALSE, out.width="50%", fig.align="center"}

### Matriz de correlación
cor_mt = cor(df_numeric_vals)
corrplot(cor_mt, type = "upper", order = "hclust", 
         tl.col = "black", tl.srt = 45)

```
En principio, se observa se evidencia que la mayoría de variables no están muy correlacionadas. Sin embargo, sí existen varios valores llamativos. El primero es la correlación entre $energy$ y $loudness$ que es igual a $0.65$, lo que significa que esta dos variables se comportan de manera similar, es decir, entre más $energy$ tenga una canción, es probable que también tenga más $loudness$.

Otro de los valores llamativos es el de la correlación entre $energy$ y $acousticness$ que es $-0.44$, lo cual implica una relación negativa entre las variables, es decir, entre más energía tenga una canción, esta será menos acústica, lo cual es muy razonable con lo que sucede en la realidad.

Finalmente, otra de las confirmaciones de los supuestos de la realidad es que entre más positiva ($valance$) sea una canción, tendrá más energía ($energy$) y será más bailable ($danceability$). Esto se puede ver reflejado con valores de correlación de $valance$ con $energy$ y $danceability$ de $0.33$ y $0.40$, respectivamente.

```{r}
cor_mt = cor(df_numeric_vals)

```



#### <a name="PCA"></a> PCA de las variables numéricas
```{r, echo=FALSE, warning=FALSE, out.width="60%", fig.align="center"}
## PCA
mod_pca = prcomp(df_numeric_vals, scale. = TRUE)
mod_pca$sdev
summary(mod_pca)

fviz_pca_var(mod_pca, 
             col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"))

```
Podemos observar como 'Loudness' y 'energy' aportan significativamente en la explicacion de la componente principal 2, al presentar una relacion alta. Si un data point tiene valores muy bajos en esas dos variables, estara ploteado en la izquiera del grafico. De forma similar, valores altos en 'valence' implican valores altos en 'danceability', aportando significativamente en el componente principal 1. 

La escala de contribucion indica que tanto una variable contribuye al componente principal. Podemos observar que hay una agrupacion de variables coloreadas con azul en el centro de los dos ejes, esto indica que todas estas variables no aportan significativamente. Esto se refleja, en el varianza explicada por los dos componentes principales, que no supera el 35% de la varianza total, incluso al ser los dos componentes principales con la mayor suma acumulada de varianza. 

-------

#### <a name="Agrupamiento-de-los-generos-musicales"></a> Agrupamiento de los géneros musicales.
Uno de los principales objetivos es predecir a qué género músical pertenece una canción basado en las siguientes variables numéricas:

* Duration_ms
* Danceability
* Energy
* Loudness
* Speechines
* Acousticness
* Instrumentalness
* Liveness
* Valence
* Tempo

##### <a name="Discriminante-lineal-de-Fisher-con-datos-puros"></a> Discriminante lineal de Fisher con datos puros

Es este punto es necesario aclarar que una de las condiciones para utilizar el discriminante de Fisher para agrupar observaciones es la homocedasticidad. Sin embargo, se hizo la prueba de la función $lda$ de R y se obtuvo el siguiente resultado. 

```{r,echo=FALSE,warning=FALSE}
# Fisher linear discriminant

# Partition dataSet (training and testing)
set.seed(123)
ind <- sample(2, nrow(datasetWithoutCategoricalFisherWithGenre),
              replace = TRUE,
              prob = c(0.75, 0.25))

training <- datasetWithoutCategoricalFisherWithGenre[ind==1,]
testing <- datasetWithoutCategoricalFisherWithGenre[ind==2,]
#dim(testing)

#View(training)
#View(datasetWithoutCategoricalFisherWithGenre)

# Things we might want to consider with LDA

# Inspecting the univariate distributions of each variable and make sure 
# that they are normally distribute. If not, you can transform them using log 
# and root for exponential distributions and Box-Cox for skewed distributions.

# removing outliers from your data and standardize the variables to make their 
# scale comparable.

modelLDA <- lda(genre~., data = training)
modelLDA
```

Matriz de Confunsión 
```{r, echo=FALSE, out.width="50%", fig.align="center"}
# Confusion matrix

nuevas_obs = subset(testing, select = -c(genre))

predicciones <- predict(object = modelLDA, newdata = nuevas_obs, method = "predictive")
t = table(testing$genre, predicciones$class, dnn = c("Clase real", "Clase predicha"))
Matriz_de_confusion = matrix(t, ncol = ncol(t), dimnames = dimnames(t))
corrplot(Matriz_de_confusion, is.corr = FALSE, col.lim = c(0, max(Matriz_de_confusion)), method = 'color', order = "hclust", 
         tl.col = "black", tl.srt = 45, tl.pos = 'lt',
         col = COL1('Blues'), cl.pos = 'b', addgrid.col = 'white', addCoef.col = 'grey50')
```
<center> y = Clase Real, x = Clase Predicha </center>


Tasa de Error Aparente
```{r, echo=FALSE}
aper = (length(testing$duration_ms)-tr(t))/length(testing$duration_ms)
aper
```

Del resultado anterior se puede concluir que el modelo del discriminante lineal de Fisher predice errórneamente el 38.55% de las veces, resultado bastante satisfactorio dado la gran diversidad de valores para cada variable que puede existir dentro de cada género.


-------


##### <a name="Discriminante-lineal-de-Fisher-con-datos-corregidos"></a> Discriminante lineal de Fisher con datos corregidos
Con el fin de comprobar la validez del modelo anterior, se hizo el siguiente arreglo de los datos:

Sea $P = [e_1, e_2, ..., e_p]$.
Se reemplaza $\textbf{X} = P\textbf{X}$ donde $\textbf{X}$ es la matriz de observaciones inicial. De esta forma, el resultado del discriminante lineal de Fisher para la variables $genre$ es:

```{r, include=FALSE}
# Remove all the categorical variables from the dataset
datasetWithoutCategorical <- dataset[,c(3,7,8,10,12:17)]

datasetWithoutCategorical <- matrix(unlist(datasetWithoutCategorical), ncol = 10, nrow = 1971)


# Get the eigenvectors of the dataset without the categorical values 
datasetWithoutCategorical.eigens <- eigen(cov(datasetWithoutCategorical))$vectors
dim(datasetWithoutCategorical.eigens)

FixedDataSetWithEqualCovariances <- datasetWithoutCategorical %*% datasetWithoutCategorical.eigens
dim(FixedDataSetWithEqualCovariances)
glimpse(FixedDataSetWithEqualCovariances)

# Convert it to dataframe
FixedDataSetWithEqualCovariances <- as.data.frame(FixedDataSetWithEqualCovariances)

# Add genre variable to the new fixed dataset
FixedDataSetWithEqualCovariancesGenre = cbind(FixedDataSetWithEqualCovariances,genre = datasetWithoutCategoricalFisherWithGenre$genre) 

FixedDataSetWithEqualCovariancesGenre = as.data.frame(FixedDataSetWithEqualCovariancesGenre)
glimpse(FixedDataSetWithEqualCovariancesGenre)
```

```{r, echo=FALSE}
# Fisher linear discriminant

# Partition dataSet (training and testing)
set.seed(123)
ind <- sample(2, nrow(FixedDataSetWithEqualCovariancesGenre),
              replace = TRUE,
              prob = c(0.75, 0.25))

training <- FixedDataSetWithEqualCovariancesGenre[ind==1,]
testing <- FixedDataSetWithEqualCovariancesGenre[ind==2,]


modelLDAEqualV <- lda(genre~., data = training)
modelLDAEqualV

```

Matriz de confusión
```{r, echo=FALSE, out.width="50%", fig.align="center"}
# Confusion matrix

nuevas_obs = subset(testing, select = -c(genre))

predicciones <- predict(object = modelLDAEqualV, newdata = nuevas_obs, method = "predictive")
t = table(testing$genre, predicciones$class, dnn = c("Clase real", "Clase predicha"))
Matriz_de_confusion = matrix(t, ncol = ncol(t), dimnames = dimnames(t))
corrplot(Matriz_de_confusion, is.corr = FALSE, col.lim = c(0, max(Matriz_de_confusion)), method = 'color', order = "hclust", 
         tl.col = "black", tl.srt = 45, tl.pos = 'lt',
         col = COL1('Blues'), cl.pos = 'b', addgrid.col = 'white', addCoef.col = 'grey50')
```
<center> y = Clase Real, x = Clase Predicha </center>

Tasa de Error Aparente
```{r, echo=FALSE}
aper = (length(testing$genre)-tr(t))/length(testing$genre)
aper
```
Nótese que los resultados con los datos corregidos son equivalentes a los resultados con los datos puros, razón por la cual se considera que la función $lda$ de R realiza un ajuste de manera automática.


-------


#### <a name="Agrupamiento-segun-nivel-de-popularidad"></a> Agrupamiento según nivel de popularidad
Por otro lado, uno de los principales objetivos de los artistas es ser muy populares, esto por esto que creó una nueva variable categórica $popularity$ basada en un índice de popularidad por canción de la siguiente manera:

| popularity | Nivel de popularidad | valor índice $i$ |
|:----------:|:----------:|:----------:|
| 0 | Baja | $0\leq i \leq 30$ |
| 1 | Media | $31\leq i \leq 60$ |
| 2 | Alta | $61\leq i \leq 86$ |

Posterior a esto, se realizó un modelo de discriminación lineal de Fisher que arrojó los siguientes resultados:

```{r, include=FALSE}
songs_normalize_genre_fixed <- read_excel("./songs_normalize_genre_fixed.xlsx", 
                                          col_types = c("text", "text", "numeric", 
                                                        "text", "numeric", "numeric", "numeric", 
                                                        "numeric", "numeric", "numeric", 
                                                        "numeric", "numeric", "numeric", 
                                                        "numeric", "numeric", "numeric", 
                                                        "numeric", "text"))
dataset <- songs_normalize_genre_fixed

###########
#Creando la nueva variable categorica de popularity
# Baja de 0 a 30 
#Media de 31 a 60
#Alta de 61-86

column_pop = songs_normalize_genre_fixed$popularity
pop_cat = songs_normalize_genre_fixed
contador = 0 #Indice para saber donde poner la nueva cat O PUEDO SIMPLEMENTE REEMPLAZAR
for (i in column_pop){
  contador = contador+1;
  if (i<=30){
    #Agregar fila con popularidad baja que es un 0
    pop_cat$popularity[contador] = 0
  }else if(i<=60){#Pues como no entro en el anterior ya es mayor a 30 
    #Agregar fila con popularidad mediaque es un 1
    pop_cat$popularity[contador] = 1
  }else{#es decir es mayor a 60 
    #Agregar fila con popularidad alta que es un 2
    pop_cat$popularity[contador] = 2
  }
}
songs_normalize_genre_fixed <- pop_cat
dataset = songs_normalize_genre_fixed
datasetWithoutCategorical <- songs_normalize_genre_fixed
#Creando la nueva variable categorica de popularity
############

# Remove Categoriccal variables from the dataset, save that new dataset
datasetWithoutCategoricalFisherWithGenre <- dataset[,c(3,7,8,10,12:18)]
datasetWithoutCategoricalFisherWithPopularity <- dataset[,c(3,6,7,8,10,12:17)]
```


```{r, echo=FALSE}
# Partition dataSet (training and testing)
set.seed(123)
ind <- sample(2, nrow(datasetWithoutCategoricalFisherWithPopularity),
              replace = TRUE,
              prob = c(0.75, 0.25))

training <- datasetWithoutCategoricalFisherWithPopularity[ind==1,]
testing <- datasetWithoutCategoricalFisherWithPopularity[ind==2,]

# Things we might want to consider with LDA

# Inspecting the univariate distributions of each variable and make sure 
# that they are normally distribute. If not, you can transform them using log 
# and root for exponential distributions and Box-Cox for skewed distributions.

# removing outliers from your data and standardize the variables to make their 
# scale comparable.

modelLDAPopularity <- lda(popularity~., data = training)
modelLDAPopularity
```

Matriz de confusión
```{r, echo=FALSE, out.width="40%", fig.align="center"}
# Confusion matrix

nuevas_obs = subset(testing, select = -c(popularity))

predicciones <- predict(object = modelLDAPopularity, newdata = nuevas_obs, method = "predictive")
t = table(testing$popularity, predicciones$class, dnn = c("Clase real", "Clase predicha"))
Matriz_de_confusion = matrix(t, ncol = ncol(t), dimnames = dimnames(t))
corrplot(Matriz_de_confusion, is.corr = FALSE, col.lim = c(0, max(Matriz_de_confusion)), method = 'color', order = "hclust", 
         tl.col = "black", tl.srt = 45, tl.pos = 'lt',
         col = COL1('Blues'), cl.pos = 'b', addgrid.col = 'white', addCoef.col = 'grey50')
```
<center> y = Clase Real, x = Clase Predicha </center>

Tasa de Error Aparente
```{r, echo=FALSE}
aper = (length(testing$duration_ms)-tr(t))/length(testing$duration_ms)
aper
```
Del resultado anterior se puede concluir que el modelo clasifica erróneamente únicamente el 33.19% de las veces. Resultado satisfactorio puesto que ayuda a estimar qué tan popular será una canción basado en sus características.


-------


#### <a name="Regresion-lineal"></a> Regresión lineal

Con el fin de estimar el índice de la variable $energy$, se realizó el modelo de regresión lineal $linear\_mod$, sin embargo, en este se encontraron muchas variables que no aportaba nada al modelo. Esto por esto que se utilizó el algoritmo $stepwise$ para encontrar el mejor modelo.
```{r, results='hide', warning=FALSE}
linear_mod = lm(energy ~ ., data = df_numeric_vals)
summary(linear_mod)

step(linear_mod, direction = "both", trace = 1)
```


Basado en los resultados del algoritmo $stepwise$, se procedió a realizar el modelo $lm\_energy$, que produjó los siguientes resultados:
```{r}
#### Linear Model para variable respuesta energy
lm_energy = lm(formula = energy ~ danceability + loudness + acousticness + 
                 instrumentalness + liveness + valence + tempo, data = df_numeric_vals)
summary(lm_energy)
```
La forma de validar el ajuste del modelo lineal es mediante el $R^2$ o coeficiente de determinacion. La medida refleja la proporcion total de la varianza explicada por el modelo de regresion. En este caso en particular, el modelo dio un coeficiente de determinacion ($R^2$) de 0.5723, esto significa que el modelo explica el 57.23% de la variabilidad total de los datos. Sin embargo, es importante resaltar que esta medida aunque no esta cerca del 100%, no implica que el modelo haya fallado. Por eso debemos observar el 'Adjusted R-squared', que da 0.5708 y tambien analizar los valores residuales.

#### Validación de supuestos del modelo

```{r, echo=FALSE, warning=FALSE, out.width="50%", fig.align="center"}
autoplot(lm_energy)
```

A partir del modelo obtenemos 4 gráficos para verificar la validez del modelo. En primer lugar, se observa como los errores no aparentan seguir un patrón muy definido, razón por la cual se podría considerar que estos son independientes. Además, en el gráfico Q-Q plot de los errores se evidencia que estos siguen una distribución normal. Estas razones nos permiten afirmar que los resultados obtenidos por el modelo son válidos.

-------


## <a name="Conclusiones"></a> Conclusiones

* Según los resultados obtenidos, podemos concluir que a pesar de que hay una gran cantidad de géneros musicales hoy en día (cada uno de ellos con su propia identidad, particularidades y propiedades), las canciones más ranqueadas en estos últimos tiempos tienden a compartir ciertas características muy semejantes unas con otras sin importar a que genero pertenezcan. Es decir, podemos observar que principalmente las canciones más ranqueadas tienden altamente a ser canciones bailables, con tonalidades positivas y alegres, que tengan cierto nivel de intensidad y que tenga un buen nivel de volumen.  
* Además, podemos observar que la mayoría de canciones que se encuentran en nuestra base de datos comparten unas características que son muy propias del género Pop o generos parcialmente similares a este, como el Hip Hop y el Rock. De hecho, estos tres géneros abarcan más del 90% de las canciones que han estado en el Top 100 de Spotify en los años analizados.
* Asímismo, podemos ver que las canciones que pertenecen a este top están muy influenciadas por las tendencias de la generación actual. En otras palabras, podemos ver claramente que cada vez las canciones con características más clásicas como lo son ser más instrumentales y acústicas tienden a difícilmente entrar en el top.  
* En conclusión, para que una canción nueva tenga altas probabilidades de que sea muy popular, esta debería tener características características muy similar a las canciones que se analizaron en este estudio, además de pertenecer a los géneros que a la gente más le gusta últimamente.

## <a name="Bibliografia"></a> Bibliografía

1. KOVERHA, M., 2022. Top Hits Spotify from 2000-2019. [online] Kaggle.com. Available at: <https://www.kaggle.com/datasets/paradisejoy/top-hits-spotify-from-20002019> [Accessed 25 May 2022].

2. SELL YOUR MUSIC WORLDWIDE. tunecore. (2022). Retrieved 25 May 2022, from https://www.tunecore.com/.

3. Ramm, R. (2022). How Much Does Spotify Pay Per 1,000 Streams In 2022 [Free Calculator]. Orpheusaudioacademy.com. Retrieved 22 May 2022, from https://www.orpheusaudioacademy.com/spotify-pay/#:~:text=You%20can%20expect%20to%20make,between%20%240.0033%20%2D%20%240.0054%20per%20stream.


