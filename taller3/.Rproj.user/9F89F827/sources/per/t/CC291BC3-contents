---
title: "Taller 3 - Parte 1"
author: "Maria Paula Gaviria & Juan Andrés Russy"
date: "26/8/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
# Punto 1
Find the maximum likelihood estimates of the $2 \times 1$ man vector $\mu$ and the $2 \times 2$ covariance matrix $\Sigma$ based on the random sample $\textbf{X}=\left(\begin{array}{cc} 3 & 6 \\ 4 & 4 \\ 5 & 7 \\ 4 & 7 \end{array}\right)$ from a bivariate normal population.  
```{r}
X <- matrix(c(3,4,5,4,
              6,4,7,7),byrow=FALSE,ncol=2)

n <- nrow(X)
p <- ncol(X)

(X.mean <- t(matrix(1,ncol=n) %*% X)/n)

D <- X - matrix(1,nrow=n) %*% t(X.mean)

(S <- (n)^(-1) * t(D)%*%D)

```


# Punto 2
Using the data $\textbf{X}=\left(\begin{array}{cc} 2 & 12 \\ 8 & 9 \\ 6 & 9 \\ 8 & 10 \end{array}\right)$.  
a. Evaluate $T^2$, for testing $H_{0}:\mu'=[7,11]$ using the data.  
```{r}
x1=c(2,8,6,8)
x2=c(12,9,9,10)

matriz=cbind(x1,x2)
k=ncol(matriz) #Numero de variables
n=nrow(matriz) #Numero de observaciones
matriz_mean=cbind(mean(x1), mean(x2))
matriz_s=cov(matriz)
matriz_sinv=solve(matriz_s)
mu0=c(7,11)
t2=n*(matriz_mean-mu0)%*%matriz_sinv%*%t(matriz_mean-mu0)


```
  $T^2$ está definida por $T^2=n(\bar{\textbf{x}}-\mu_0)'\textbf{S}^{-1}(\bar{\textbf{x}}-\mu_0)$. En este caso tenemos que $n=`r n`$, $(\bar{\textbf{x}}-\mu_0)'= \left(\begin{array}{cc} -1 & -1 \end{array}\right)$, $\textbf{S}=\left(\begin{array}{cc} `r matriz_s[1]` & `r matriz_s[2]` \\ `r matriz_s[3]` & `r matriz_s[4]` \end{array}\right)$ y $\textbf{S}^{-1}=\left(\begin{array}{cc} `r matriz_sinv[1]` & `r matriz_sinv[2]` \\ `r matriz_sinv[3]` & `r matriz_sinv[4]` \end{array}\right)$. De esta manera, $T^2=4\left(\begin{array}{cc} -1 & -1 \end{array}\right)\left(\begin{array}{cc} `r matriz_sinv[1]` & `r matriz_sinv[2]` \\ `r matriz_sinv[3]` & `r matriz_sinv[4]` \end{array}\right)\left(\begin{array}{} -1 \\ -1 \end{array}\right)=`r t2`$.

b. Specify the distribution of $T^2$ for the situation (a).  
  El estadístico $T^2$ tiene distribución $\frac{(n-1)p}{(n-p)}F_{p,n-p}$. Luego nuestro stadístico $T^2$ tiene distribución $\frac{(`r n`-1)`r k`}{(`r n`-`r k`)}F_{`r k`,`r n`-`r k`}=\frac{`r (n-1)*k`}{`r n-k`}F_{`r k`,`r n-k`}=`r ((n-1)*k)/(n-k)`F_{`r k`,`r n-k`}$.

c. Using (a) and (b), test $H_{0}$ at the $\alpha=0.05$ level. What conclusion do you reach?  
```{r}
#Valor crítico
alpha = 0.05 # Nivel de significancia
critical.value = (k*(n-1))/(n-k)*qf(1-alpha,k,n-k)

```

  Del punto (a) tenemos que nuestro estadístico es $T^2=`r t2`$ y de (b) tenemos que nuestro valor crítico es $`r ((n-1)*k)/(n-k)`F_{`r k`,`r n-k`}(0.05)=`r ((n-1)*k)/(n-k)`(`r qf(1-alpha,k,n-k)`)=`r critical.value`$. Note que nuestro estadístico es menor que el valor crítico $`r t2`< `r critical.value`$, luego no rechazamos $H_0:\mu=\mu_0$ con un nivel de significancia del 5%.
  
d. Determine $\Lambda$. 
```{r}
#Matriz sigma_0
s11_0=((matriz[1]-mu0[1])^2+(matriz[2]-mu0[1])^2+(matriz[3]-mu0[1])^2+(matriz[4]-mu0[1])^2)/(n-1)
s22_0=((matriz[5]-mu0[2])^2+(matriz[6]-mu0[2])^2+(matriz[7]-mu0[2])^2+(matriz[8]-mu0[2])^2)/(n-1)
s12_0=((matriz[1]-mu0[1])*(matriz[5]-mu0[2])+(matriz[2]-mu0[1])*(matriz[6]-mu0[2])+(matriz[3]-mu0[1])*(matriz[7]-mu0[2])+(matriz[4]-mu0[1])*(matriz[8]-mu0[2]))/(n-1)

x1_0=c(s11_0, s12_0)
x2_0=c(s12_0, s22_0)
matriz_s0=cbind(x1_0,x2_0)

lambda=(det(matriz_s)/det(matriz_s0))^(n/2)

```

  Sabemos que $\Lambda=(\frac{\Sigma}{\Sigma_0})^{n/2}$. Remplazando nos da que $\Lambda=`r lambda`$.  
  
  
e. Using the Wilk's Lambda (d), calculate $T^2$.  
  Sabemos de la lambda de Wilks es de la forma $\Lambda^{2/n}=(1+\frac{T^2}{(n-1)})^{-1}$, luego si despejamos $T^2$, tenemos  $T^2=(\Lambda^{\frac{-2}{n}}-1)(n-1)$. Remplazando tenemos que $T^2= `r (lambda^(-2/n)-1)*(n-1)`$.  
  
# Punto 3
Harry Roberts, a naturalist for the Alaska Fish and Game department, studies grizzly bears with the goal of maintaining a healthy population. Measurements on $n=61$ bears provided the following summary statistics:  
<style type="text/css">
.tg  {border-collapse:collapse;border-spacing:0;}
.tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  overflow:hidden;padding:10px 5px;word-break:normal;}
.tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px;
  font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;}
.tg .tg-c3ow{border-color:inherit;text-align:center;vertical-align:top}
</style>
<table class="tg">
<thead>
  <tr>
    <th class="tg-c3ow">Variable</th>
    <th class="tg-c3ow">Weight(kg)</th>
    <th class="tg-c3ow">Body length(cm)</th>
    <th class="tg-c3ow">Neck</th>
    <th class="tg-c3ow">Girth</th>
    <th class="tg-c3ow">Head length</th>
    <th class="tg-c3ow">Head width</th>
  </tr>
</thead>
<tbody>
  <tr>
    <td class="tg-c3ow">Sample</td>
    <td class="tg-c3ow"></td>
    <td class="tg-c3ow"></td>
    <td class="tg-c3ow"></td>
    <td class="tg-c3ow"></td>
    <td class="tg-c3ow"></td>
    <td class="tg-c3ow"></td>
  </tr>
  <tr>
    <td class="tg-c3ow">mean</td>
    <td class="tg-c3ow">95.52</td>
    <td class="tg-c3ow">164.38</td>
    <td class="tg-c3ow">55.69</td>
    <td class="tg-c3ow">93.39</td>
    <td class="tg-c3ow">17.98</td>
    <td class="tg-c3ow">31.13</td>
  </tr>
</tbody>
</table>

Covariance matrix $S=\left(\begin{array}{cccccc} 3266.46 & 1343.97 & 731.54 & 1175.50 & 162.68 & 238.37 \\ 1343.97 & 721.91 & 324.25 & 537.35 & 80.17 & 117.73 \\ 731.54 & 324.25 & 179.28 & 281.17 & 39.15 & 56.80 \\ 1175.50 & 537.35 & 281.17 & 474.98 & 63.73 & 94.85 \\ 162.68 & 80.17 & 39.15 & 63.73 & 9.95 & 13.88 \\ 238.37 & 117.73 & 56.80 & 94.85 & 13.88 & 21.26 \end{array}\right)$ 

```{r}
X_bar = matrix(c(95.52,164.38, 55.69, 93.39, 17.98, 31.13), ncol = 1)
S = matrix(c(3266.46, 1343.97, 731.54, 1175.50, 162.68, 238.37,
             1343.97, 721.91, 324.25, 537.35, 80.17, 117.73,
             731.54, 324.25, 179.28, 281.17, 39.15, 56.80,
             1175.50, 537.35, 281.17, 474.98, 63.73, 94.85,
             162.68, 80.17, 39.15, 63.73, 9.95, 13.88,
             238.37, 117.73, 56.80, 94.85, 13.88, 21.26),byrow=TRUE,ncol=6)
```


a.  Obtain the large sample 95% simultaneous confidence intervals for the six populations mean body measurements. 
```{r}
# a)
a_vectors = diag(6)
p = nrow(X_bar)
n = 61
alpha = 0.05
constant = (p*(n-1))/(n*(n-p))
estadistico = qf(alpha,p,n-p,lower.tail = F)

lim_inferior = c()
lim_superior = c()
for (i in 1:6){
  a = a_vectors[,i]
  termino_1 = t(a) %*% X_bar
  raiz_2 = sqrt(constant * estadistico * t(a) %*% S %*% a)
  lim_inferior = append(lim_inferior,termino_1 - raiz_2)
  lim_superior = append(lim_superior,termino_1 + raiz_2)
}

simultaneous_CI = matrix(c(lim_inferior,lim_superior),ncol = 2)
simultaneous_CI
```

b.  Obtain the large sample 95% simultaneous confidence ellipse for mean weight and mean girth.
```{r}
# b)
X_barb = matrix(c(X_bar[1,1], X_bar[4,1]), ncol = 1)
Sb = matrix(c(S[1,1], S[1,4], S[4,1],S[4,4]),byrow=TRUE,ncol=2)

library(plotrix)
angle <- atan(eigen(Sb)$vectors[2,1]/eigen(Sb)$vectors[1,1]) 
plot(0,pch='',ylab='',xlab='',xlim=c(65,125),ylim=c(80,110))
axis1 <- sqrt(eigen(Sb)$values[1])*
  sqrt(
    (p*(n-1))/
      (n*(n-p))* # no es el mismo valor critico que antes 
      qf(1-alpha,p,n-p)) 

axis2 <- sqrt(eigen(Sb)$values[2])*
  sqrt((p*(n-1))/(n*(n-p))*qf(1-alpha,p,n-p))
lengths <- c(axis1,axis2)
draw.ellipse(x=X_barb[1,1],y=X_barb[2,1],a=lengths[1],b=lengths[2],angle=angle,deg=FALSE)
```

c.  Obtain 95% Bonferroni confidence intervals for the six means in part (a).
```{r}
# c)
b <- 6
t.bonf <- qt(1-alpha/(2*b),df=n-1)

lim_inferior = c()
lim_superior = c()
for (i in 1:6){
  termino_1 = X_bar[i,]
  termino_2 = t.bonf * sqrt(S[i,i]/n)
  lim_inferior = append(lim_inferior,termino_1 - termino_2)
  lim_superior = append(lim_superior,termino_1 + termino_2)
}

bonferroni_CI = matrix(c(lim_inferior,lim_superior),ncol = 2)
bonferroni_CI
```

d.  Refer to part (b). Construct the 95% Bonferroni confidence rectangle for the mean weight and mean girth using $m=6$. Compare this rectangle with the confidence ellipse in part (b).
```{r}
# d)
plot(0,pch='',ylab='',xlab='',xlim=c(65,125),ylim=c(80,110))
draw.ellipse(x=X_barb[1,1],y=X_barb[2,1],a=lengths[1],b=lengths[2],angle=angle,deg=FALSE)

l1 = simultaneous_CI[1,1]
u1 = simultaneous_CI[1,2]
l2 = simultaneous_CI[4,1]
u2 = simultaneous_CI[4,2]
abline(v=l1,lty=3);abline(v=u1,lty=3)
abline(h=l2,lty=3);abline(h=u2,lty=3)

l1b = bonferroni_CI[1,1]
u1b = bonferroni_CI[1,2]
l2b = bonferroni_CI[4,1]
u2b = bonferroni_CI[4,2]
abline(v=l1b,lty=2);abline(v=u1b,lty=2)
abline(h=l2b,lty=2);abline(h=u2b,lty=2)

```

