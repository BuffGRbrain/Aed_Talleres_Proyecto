---
title: "T4_aed_Cabrera_Rodriguez_Ribero"
author: "Rafael Cabrera, Juan Camilo Rodriguez, Guillermo Ribero"
date: '2022-03-11'
output: html_document
---

#### 1 Un investigador considera tres índices para medir la severidad de los ataques corazón. Los valores de esos indices para $n=40$ pacientes con ataque al corazón que llegan a las emergencias de un hospital producen las siguientes estadísticas resumidas.

$$
\overline{\mathbf{x}}=\left[\begin{array}{l}
46.1 \\
57.3 \\
50.4
\end{array}\right] \text { y } \mathbf{S}=\left[\begin{array}{rrr}
101.3 & 63.0 & 71.0 \\
63.0 & 80.2 & 55.6 \\
71.0 & 55.6 & 97.4
\end{array}\right]
$$

#### (a) Los tres índices son evaluados para cada paciente. Realice una prueba para la igualdad de las medias de los indices con $\alpha=0.05$.

```{r}
alpha = 0.05
n=40
q = 3
X_barra = c(46.1, 57.3, 50.4)
S = matrix(c(101.3, 63.0, 71.0, 63.0, 80.2, 55.6, 71.0, 55.6, 97.4), nrow = 3, ncol=3)

C = rbind(c(1,-1,0),c(0,1,-1))

T_square = (n*t(C%*%X_barra)%*%solve(C%*%S%*%t(C))%*%(C%*%X_barra))[1,1]

fract = ((n-1)*(q-1))/(n-q+1)
F_q_n = qf(1-alpha, df1 = q-1,df2=n-q+1)

fract_F = fract * F_q_n
T_square
fract_F
```
Nótese que $T^2 = `r T_square` >> `r fract_F`$, por lo tanto, las medias no son igual con un nivel de confianza de 0.95.

#### (b) Juzgue las diferencias entre pares de las medias de los índices usando intervalos de confianza $\left(T^{2}\right)$ simultáneos del $95 \%$.


```{r}
alpha = 0.05
n=40
q=3
X_barra = c(46.1, 57.3, 50.4)
S = matrix(c(101.3, 63.0, 71.0, 63.0, 80.2, 55.6, 71.0, 55.6, 97.4), nrow = 3, ncol=3)
D_M = matrix(data = NA, nrow = 3, ncol = 2)
fract = ((n-1)*(q-1))/(n-q+1)
C_matrix = rbind(c(1,-1,0), c(1,0,-1), c(0,1,-1))
F_q_n = qf(1-alpha, df1 = q-1,df2=n-q+1)

for (i in 1:3){
  c = C_matrix[i,]
  CSC_N_S = sqrt((t(c)%*%S%*%c)/n)
  
  D_M[i,1] = t(c)%*%X_barra + sqrt(fract*F_q_n)*CSC_N_S
  D_M[i,2] = t(c)%*%X_barra - sqrt(fract*F_q_n)*CSC_N_S
} 
D_M
```


#### 2. Observaciones sobre dos respuestas fueron coleccionadas para dos tratamientos Las observaciones vectoriales $[x 1, x 2]^{\prime}$ fueron:

Tratamiento 2:
$$Tratamiento-2:\left[\begin{array}{l}3 \\ 3\end{array}\right], \quad\left[\begin{array}{l}1 \\ 6\end{array}\right], \quad\left[\begin{array}{l}2 \\ 3\end{array}\right]$$

Tratamiento 3:
$$Tratamiento-3:\left[\begin{array}{l}2 \\ 3\end{array}\right],\left[\begin{array}{l}5 \\ 1\end{array}\right], \quad\left[\begin{array}{l}3 \\ 1\end{array}\right], \quad\left[\begin{array}{l}2 \\ 3\end{array}\right]$$



#### (a) Calcule $\boldsymbol{S}_{\text {pooled }}$

```{r}
n2 = 3
n3 = 4
p = 2


X2_1 <- c(3,1,2)
X2_2 <- c(3,6,3)
X2 = t(rbind(X2_1,X2_2))

X3_1 <- c(2,5,3,2)
X3_2 <- c(3,1,1,3)
X3 = t(rbind(X3_1,X3_2))

#Cada fila es una variable
S2 = cov(X2)
  
S3 = cov(X3)

Spooled =  (( ((n2-1)*S2) + ((n3-1)*S3) ) / (n2+n3-2))

Spooled
```


#### (b) Realice la prueba $H_{0}: \boldsymbol{\mu}{2}-\boldsymbol{\mu}{3}=\mathbf{0}$ usando un enfoque de dos muestras con $\alpha=.01$.



```{r}
#Ho => Mu2 = Mu3 es decir delta_0 es = 0
alpha = 0.01
X2_barra = rbind(mean(X2_1),mean(X2_2))
  
X3_barra = rbind(mean(X3_1),mean(X3_2))

#Como n-p es 1 y 2 respectivamente, es decir no es grande entonces asumimos normalidad para usar Tsquared

frac = (n3+n2)/(n3*n2)

Tsqared = t(X2_barra-X3_barra) %*% solve(frac*Spooled) %*% (X2_barra-X3_barra)

frac2 = (p*(n2+n3-2) ) / (n2+n3-p-1)

f_p_n_n = qf(1-alpha, p, (n2+n3-p-1))

c_squared = f_p_n_n * frac2


#Si Tsqared es mayor a 45 entonces no se acepta la prueba de hipótesis con una confianza del 99%

if (Tsqared > c_squared) {
  print("No se acepta la prueba de hipótesis con una confianza del 99%")
} else {
 print("Se acepta la prueba de hipótesis con una confianza del 99%") 
}

```


#### (c) Construya un intervalo de confianza simultáneo $\left(T^{2}\right)$ del $99 \%$ para las diferencias $\mu_{2 i}-\mu_{3 i}, i=1,2$

```{r}
c = sqrt(c_squared)
#Falta corregir que reciba una raiz negativa para que pueda calcular los limites o talvez haya un error en Spooled
a = c(1,0) #Para la variable 1
low_lim = (t(a) %*% (X2_barra - X3_barra) ) + (c * sqrt( frac * t(a) %*% Spooled %*% a))
upp_lim = (t(a) %*% (X2_barra - X3_barra) ) - (c * sqrt( frac * t(a) %*% Spooled %*% a))

intervalo = c(low_lim,upp_lim) 
print('Intervalo para el tratamiento 2')
print(t(intervalo))

a = c(0,1) #Para la variable 2
low_lim = (t(a) %*% (X2_barra - X3_barra) ) + (c * sqrt( frac * t(a) %*% Spooled %*% a))
upp_lim = (t(a) %*% (X2_barra - X3_barra) ) - (c * sqrt( frac * t(a) %*% Spooled %*% a))

intervalo = c(low_lim,upp_lim)

print('Intervalo para el tratamiento 2')
print(t(intervalo))

```


#### 3. Dados los datos
$$
\begin{array}{l|rrrrrr}
z_{1} & 10 & 5 & 7 & 19 & 11 & 18 \\
z_{2} & 2 & 3 & 3 & 6 & 7 & 9 \\
\hline y & 15 & 9 & 3 & 25 & 7 & 13
\end{array}
$$

#### (a) Ajuste el modelo de regresión lineal

$$
Y_{j}=\beta_{0}+\beta_{1} z_{j 1}+\beta_{2} z_{j 2}+\varepsilon_{j}, \quad j=1,2, \ldots, 6
$$
```{r}
r = 2
n = 6
alpha = 0.05

z_0 = c(1,1,1,1,1,1)
z1 = c(10,5,7,19,11,18)
z2 = c(2,3,3,6,7,9)
Z = cbind(z_0,z1,z2)

Y = c(15,9,3,25,7,13)

B_est = solve(t(Z)%*%Z)%*%t(Z)%*%Y

Y_est = Z%*%B_est

E_est = Y - Y_est
```

De esta forma, el modelo queda ajustado de la siguiente forma:
$$
Y_{j}=2.14+1.78 z_{j 1}-2.18 z_{j 2}+\varepsilon_{j}, \quad j=1,2, \ldots, 6\\
$$
donde $$\varepsilon ' = (`r E_est`)$$

#### (b) Determine los intervalos de confianza del $95 \%$ simultáneos (uno a la vez) para $\beta_{1} \mathrm{y} \beta_{2}$.

```{r}
#Intervalo de confianza para b1
S_square = (t(E_est) %*%(E_est))/(n-r-1)
S_square = S_square[1,1]

SZZ = S_square*solve(t(Z)%*%Z)
F_r_n = qf(1-alpha, df1 = r+1, df2=n-r-1)

lw_lm_b1 = B_est[2] - sqrt(SZZ[2,2]) * sqrt((r+1)*F_r_n)
upp_lm_b1 = B_est[2] + sqrt(SZZ[2,2]) * sqrt((r+1)*F_r_n)

#Intervalo de confianza para b2
S_square = (t(E_est) %*%(E_est))/(n-r-1)
S_square = S_square[1,1]

SZZ = S_square*solve(t(Z)%*%Z)
F_r_n = qf(1-alpha, df1 = r+1, df2=n-r-1)

lw_lm_b2 = B_est[3] - sqrt(SZZ[3,3]) * sqrt((r+1)*F_r_n)
upp_lm_b2 = B_est[3] + sqrt(SZZ[3,3]) *sqrt((r+1)*F_r_n)
```

De esta forma, se tiene que el intervalo de confianza simultáneo del 95% para $\beta_{1} = [-0.84, 4.41]$, y para $\beta_2 = [-7.13, 3.26]$. Una de las razones de la amplitud de estos intervalos puede ser que $n$ es muy pequeño.

#### (c) Comprueba la prueba de hípótesis nula de que sólo el coeficiente $\beta_{1}$ es cero.

```{r}
reg = lm(Y~z1+z2)
summary(reg)
```
Hay varias cosas por analizar de este modelo. La primera es que el valor-p es mayor a 0.05, por tanto, no se rechaza $H_0$, es decir, los coeficientes son igual a 0 con un 95% de confianza. Por otro lado, en el modelo también se puede observar que el valor-p para $\beta_1 < \alpha$ en la prueba invidual, por tanto, se podría concluir que $\beta_1$ sí es significativo para el modelo, es decir, $\beta_1 \neq 0$. Esta contradicción puede deberse que $n$ es muy pequeño.

#### (d) Determine el valor esperado de la predicción $(E(Y))$ para $z_{1}=6 \mathrm{y}_{2}=$ 4. Calcule su intervalo de confianza del $95 \%$ correspondiente (el del valor esperado).

```{r}
z0 = c(1, 6, 4)
EV_Y = t(z0)%*%B_est # Valor esperado

tstudent = qt((1-alpha/2),df = n-r-1 )
S_square_ph = (t(Y-Z%*%B_est)%*%(Y-Z%*%B_est))/(n-r-1)
S_square_ph = S_square_ph[1,1]

#Intervalo de confianza del valor esperado
EV_lw_lm = t(z0)%*%B_est - tstudent*sqrt((t(z0)%*%solve(t(Z)%*%Z)%*%z0)%*%S_square_ph)
EV_upp_lm = t(z0)%*%B_est + tstudent*sqrt((t(z0)%*%solve(t(Z)%*%Z)%*%z0)%*%S_square_ph)
```
El valor esperado de la predicción es `r EV_Y`. Y el intervalo de confianza del 95% para el valor esperado es $[-4.70, 12.88]$.

#### (e) Determine el intervalo de confianza del $95 \%$ para la predicción $(Y)$ cuando $z_{1}=6 \mathrm{y} z_{2}=4$.

```{r}
#Limites para Y
Y_lw_lm = t(z0)%*%B_est - tstudent*sqrt(S_square_ph%*%(1+t(z0)%*%solve(t(Z)%*%Z)%*%z0))
Y_upp_lm = t(z0)%*%B_est + tstudent*sqrt(S_square_ph%*%(1+t(z0)%*%solve(t(Z)%*%Z)%*%z0))
```
El intervalo de confianza para Y es $[-11.96, 20.13]$.

#### 4. La librería MASS (carguela con library (MASS)) contiene el dataset de Boston, el cual registró la variable medv (valor medio de una casa) para 506 barrios en Boston. En este ejercicio, se buscará predecir la variable medv usando 13 predictores tales como: rm (número promedio de habitaciones por casa), age (promedio de la edad de las casas), y lstat (porcentaje de hogares con bajo nivel socioeconómico).

#### Para este ejercicio puede usar la función lm de $\mathrm{R}$.

#### (a) Realice el ajuste de regresión lineal simple usando como variable independiente lstat. Realice un resumen de los resultados (use la función summary). ¿Es la pendiente (coeficiente asociado a lstat) cero? Justifique estadísticamente su respuesta.

```{r}
library(MASS)
data(Boston)
modelo=lm(medv~lstat, data=Boston) 
summary(modelo)
```

Con el resumen de los resultados que nos arrojó la función summary podemos observar que el valor del coeficiente asociado a lsat es igual a -0.95005, el cual es evidentemente diferente de cero. Por lo que esto significa que la variable independiente lsat influye en la variable dependiente mdev

#### (b) Determine el intervalo de confianza del $95 \%$ para los coeficientes (use la función confint().

```{r}
confint(modelo,level=0.95)
```


#### (c) Realice las predicciones para el valor esperado de medv y los correspondientes intervalos de confianza del $95 \%$ para los valores de lstat=c $(5,10,15)$. Sugerencia: use predict(). Determine el intervalo de confianza para la predicción (no el valor esperado).

```{r}
prediccion = data.frame(lstat=c(5,10,15))
predict(modelo,prediccion,interval='confidence',level=0.95)
```


#### (d) Grafique el diagrama de dispersion de medv y lstat y la recta de regresión (use abline).

```{r}
plot(Boston$lstat,Boston$medv,main="scatterplot")
abline(modelo,col='red')
```


#### (e) Realice la regresión lineal de medv utilizando todas las variables independientes. Determine los intervalos de confianza del $95 \%$ de los coeficientes asociados a las variables independientes.

```{r}
modelo_2 = lm(medv~.,data=Boston)
summary(modelo_2)
```
```{r}
confint(modelo_2,level=0.95)
```


#### (f) Con el modelo anterior (e) determine el intervalo de confianza del $95 \%$ del valor esperado de medv para el valor promedio de las variables independientes. Ahora, determine el intervalo de confianza del $95 \%$ para la predicción usando el mismo vector de entrada.

```{r}
Modelo2_limpio <- lm(medv ~ ( crim + zn + chas + nox + rm + dis + rad + tax + ptratio + black +lstat), data = Boston)
summary(Modelo2_limpio)
```

```{r}
X <- as.matrix(Boston[,colnames(Boston)!="medv"])
X_bar <-(1/dim(X)[1])*t( X )%*% matrix( 1, dim( X )[1],1)
X_bar
```

```{r}
predict(Modelo2_limpio, data.frame(t( X_bar ) ), interval="confidence")
predict(Modelo2_limpio, data.frame( t( X_bar ) ), interval="prediction")
```


#### 5. Se realizan observaciones de dos respuestas sobre tres tratamientos. Los vectores de observación $\left[\begin{array}{l}x_{1} \\ x_{2}\end{array}\right]$ son:

##### Tratamiento 1: 

$$
\left[\begin{array}{l}2 \\ 9\end{array}\right],\left[\begin{array}{l}3 \\ 2\end{array}\right],\left[\begin{array}{l}7 \\ 5\end{array}\right],\left[\begin{array}{l}2 \\ 1\end{array}\right],\left[\begin{array}{l}7 \\ 5\end{array}\right]
$$

##### Tratamiento 2: 
$$
\left[\begin{array}{l}3 \\ 2\end{array}\right], \quad\left[\begin{array}{l}2 \\ 4\end{array}\right],\left[\begin{array}{l}9 \\ 4\end{array}\right]
$$

##### Tratamiento 3: 

$$
\left[\begin{array}{l}1 \\ 4\end{array}\right],\left[\begin{array}{l}7 \\ 2\end{array}\right],\left[\begin{array}{l}4 \\ 9\end{array}\right],\left[\begin{array}{l}3 \\ 2\end{array}\right]
$$

#### (a) Construya la tabla de one-way MANOVA.

```{r}
#LIFEHACK DEJAR LA MATRIZ CON HUECOS(Rellenar con 0's)
#nl = 2 #Total de obs
g = 3 #Pues son 3 tratamientos
l = 2 #Pues son 2 variables
#XTrat_Variable
X1_1 = c(2,3,7,2,7)
X1_2 = c(9,2,5,1,5)

X2_1 = c(3,2,9)
X2_2 = c(2,4,4)

X3_1 = c(1,7,4,3)
X3_2 = c(4,2,9,2)

#Vector con las n de cada tratamiento
n_l = c(length(X1_1), length(X2_1), length(X3_1))

#Agrupadas por variables 1 y 2
X_l_1 = c(X1_1,X2_1,X3_1)
X_l_2 = c(X1_2,X2_2,X3_2)

Matriz_obs = cbind(X_l_1, X_l_2)
#SSOBS para cada variable
# la suma de los cuadrados 
#de cada observación de una variable
SSobs_1 = sum(X_l_1**2)
SSobs_2 = sum(X_l_2**2)

#Media total de cada variable en los 3 tratamientos
media_total_1 = mean(X_l_1)
media_total_2 = mean(X_l_2)

ss_mean_1 = length(X_l_1) * (media_total_1**2)
ss_mean_2 = length(X_l_2) * (media_total_2**2)

#Medias de cada variable en cada tratamiento
X1_1_Barra = mean(X1_1)
X1_2_Barra = mean(X1_2)

X2_1_Barra = mean(X2_1)
X2_2_Barra = mean(X2_2)

X3_1_Barra = mean(X3_1)
X3_2_Barra = mean(X3_2)

#vector con promedios de variable 1 para cada tratamiento
X_barras_1 = c(X1_1_Barra, X2_1_Barra, X3_1_Barra)
#vector con promedios de variable 2 para cada tratamiento
X_barras_2 = c(X1_2_Barra, X2_2_Barra, X3_2_Barra)


####Construyendo las matrices X_l y X_barra_total para cada variable

#Construimos las matrices X_l y X_barra_l para la primera variable
x_l_1 = c(X1_1_Barra, X1_2_Barra)
x_l_2 = c(X2_1_Barra, X2_2_Barra)
x_l_3 = c(X3_1_Barra, X3_2_Barra)

X_barra_total = c(media_total_1, media_total_2)

#SS treatment effect para varibale 1
ss_treatment_1 = (length(X1_1)*((X1_1_Barra-media_total_1)**2)) + (length(X2_1)*((X2_1_Barra-media_total_1)**2)) +(length(X3_1)*((X3_1_Barra-media_total_1)**2))

#SS treatment effect para varibale 2
ss_treatment_2 = (length(X1_2)*((X1_2_Barra-media_total_2)**2)) + (length(X2_2)*((X2_1_Barra-media_total_2)**2)) +(length(X3_2)*((X3_1_Barra-media_total_2)**2))

#SS residual para varibale 1
ss_res_1 = sum((X1_1-X1_1_Barra)**2)+sum((X2_1-X2_1_Barra)**2)+sum((X3_1-X3_1_Barra)**2)

#SS residual para varibale 2
ss_res_2 = sum((X1_2-X1_2_Barra)**2)+sum((X2_2-X2_2_Barra)**2)+sum((X3_2-X3_2_Barra)**2)

#Total SS corrected para variable 1
ss_corrected_1 = ss_treatment_1 + ss_res_1

#Total SS corrected para variable 2
ss_corrected_2 = ss_treatment_2 + ss_res_2

##Para los grados de libertad
n_1 = n_2 = length(X1_1)+length(X2_1)+length(X3_1)

#Creando la matriz B y W
B = n_l[1]*(x_l_1-X_barra_total)%*%t(x_l_1-X_barra_total) + n_l[2]*(x_l_2-X_barra_total)%*%t(x_l_2-X_barra_total) + n_l[3]*(x_l_3-X_barra_total)%*%t(x_l_3-X_barra_total)

#Construyendo W
W = matrix(data = 0, nrow = 2, ncol = 2)

c = 0
x_l_b_t = x_l_1
for (t in 1:n_1){
  c = c +1
  W = W + ((Matriz_obs[t,] - x_l_b_t)%*%t(Matriz_obs[t,] - x_l_b_t))
  if (c == 5){
    x_l_b_t = x_l_2
  }
  
  if (c == 8){
    x_l_b_t = x_l_3
  }

}

Total_total = B+W

B
W
B+W
```

$$
\begin{array}{cccc}
\text { Source of variation } & \text { Matrix of SS and CP}& \text { d.f. } \\
\text { Treatment } & B & 3-1\\
\hline \text { Residual } & W & 12-3\\
\hline \text { Total (corrected for the mean) } & B+W & 12-1\\
\end{array}
$$


#### (b) Evalue el Lambda de Wilk, $\Lambda *$, y realice una prueba de hipótesis sobre los efectos de tratamientos. Sea $\alpha=.05$.

```{r}
alpha = 0.05
Lamba_w = (det(W)/det(Total_total))
Lamba_w
#Para hacer el test de la prueba de hipótesis, nos referimos a la table 6.3 del libro para el caso p = 2 y g = 3

PH = ((1-sqrt(Lamba_w))/(sqrt(Lamba_w)))*((n_1-g-1)/(g-1))

F_punto_5 = qf(1-alpha, df1 = 2*(g-1),df2=2*(n_1-g-1))

if (PH>F_punto_5){
print("Rechazamos H0, concluimos que hay efecto de los tratamientos")
}else{print("No rechamos H0, concluimos que no hay efecto de los tratamientos.")}
```


#### (c) Repita la prueba considerando que la muestra es grande.

```{r}
alpha = 0.05
n_grande = 100
Lamba_w = (det(W)/det(Total_total))

#Para hacer el test de la prueba de hipótesis, nos referimos a la table 6.3 del libro para el caso p = 2 y g = 3

PH_grande = -(n_grande-1-((p+g)/2))*log(Lamba_w)
chi_s = qchisq(1-alpha, p*(g-1))

if (PH_grande>chi_s){
print("Rechazamos H0, concluimos que hay efecto de los tratamientos")
}else{print("No rechamos H0, concluimos que no hay efecto de los tratamientos.")}
```